// Code generated by protoc-gen-go. DO NOT EDIT.
// source: kafka/grpc/kafka.proto

package kafka

import (
	context "context"
	fmt "fmt"
	proto "github.com/golang/protobuf/proto"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	math "math"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package

type ProduceRequest struct {
	Cluster              string   `protobuf:"bytes,1,opt,name=cluster,proto3" json:"cluster,omitempty"`
	Topic                string   `protobuf:"bytes,2,opt,name=topic,proto3" json:"topic,omitempty"`
	Message              []byte   `protobuf:"bytes,3,opt,name=message,proto3" json:"message,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *ProduceRequest) Reset()         { *m = ProduceRequest{} }
func (m *ProduceRequest) String() string { return proto.CompactTextString(m) }
func (*ProduceRequest) ProtoMessage()    {}
func (*ProduceRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_1f475d2b3bc19ab6, []int{0}
}

func (m *ProduceRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ProduceRequest.Unmarshal(m, b)
}
func (m *ProduceRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ProduceRequest.Marshal(b, m, deterministic)
}
func (m *ProduceRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ProduceRequest.Merge(m, src)
}
func (m *ProduceRequest) XXX_Size() int {
	return xxx_messageInfo_ProduceRequest.Size(m)
}
func (m *ProduceRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_ProduceRequest.DiscardUnknown(m)
}

var xxx_messageInfo_ProduceRequest proto.InternalMessageInfo

func (m *ProduceRequest) GetCluster() string {
	if m != nil {
		return m.Cluster
	}
	return ""
}

func (m *ProduceRequest) GetTopic() string {
	if m != nil {
		return m.Topic
	}
	return ""
}

func (m *ProduceRequest) GetMessage() []byte {
	if m != nil {
		return m.Message
	}
	return nil
}

type ProduceRes struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *ProduceRes) Reset()         { *m = ProduceRes{} }
func (m *ProduceRes) String() string { return proto.CompactTextString(m) }
func (*ProduceRes) ProtoMessage()    {}
func (*ProduceRes) Descriptor() ([]byte, []int) {
	return fileDescriptor_1f475d2b3bc19ab6, []int{1}
}

func (m *ProduceRes) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ProduceRes.Unmarshal(m, b)
}
func (m *ProduceRes) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ProduceRes.Marshal(b, m, deterministic)
}
func (m *ProduceRes) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ProduceRes.Merge(m, src)
}
func (m *ProduceRes) XXX_Size() int {
	return xxx_messageInfo_ProduceRes.Size(m)
}
func (m *ProduceRes) XXX_DiscardUnknown() {
	xxx_messageInfo_ProduceRes.DiscardUnknown(m)
}

var xxx_messageInfo_ProduceRes proto.InternalMessageInfo

type ConsumeRequest struct {
	Cluster              string   `protobuf:"bytes,1,opt,name=cluster,proto3" json:"cluster,omitempty"`
	Group                string   `protobuf:"bytes,2,opt,name=group,proto3" json:"group,omitempty"`
	Topic                string   `protobuf:"bytes,3,opt,name=topic,proto3" json:"topic,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *ConsumeRequest) Reset()         { *m = ConsumeRequest{} }
func (m *ConsumeRequest) String() string { return proto.CompactTextString(m) }
func (*ConsumeRequest) ProtoMessage()    {}
func (*ConsumeRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_1f475d2b3bc19ab6, []int{2}
}

func (m *ConsumeRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ConsumeRequest.Unmarshal(m, b)
}
func (m *ConsumeRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ConsumeRequest.Marshal(b, m, deterministic)
}
func (m *ConsumeRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ConsumeRequest.Merge(m, src)
}
func (m *ConsumeRequest) XXX_Size() int {
	return xxx_messageInfo_ConsumeRequest.Size(m)
}
func (m *ConsumeRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_ConsumeRequest.DiscardUnknown(m)
}

var xxx_messageInfo_ConsumeRequest proto.InternalMessageInfo

func (m *ConsumeRequest) GetCluster() string {
	if m != nil {
		return m.Cluster
	}
	return ""
}

func (m *ConsumeRequest) GetGroup() string {
	if m != nil {
		return m.Group
	}
	return ""
}

func (m *ConsumeRequest) GetTopic() string {
	if m != nil {
		return m.Topic
	}
	return ""
}

type ConsumeRes struct {
	Partition            int32    `protobuf:"varint,1,opt,name=partition,proto3" json:"partition,omitempty"`
	Offset               int64    `protobuf:"varint,2,opt,name=offset,proto3" json:"offset,omitempty"`
	Value                []byte   `protobuf:"bytes,3,opt,name=value,proto3" json:"value,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *ConsumeRes) Reset()         { *m = ConsumeRes{} }
func (m *ConsumeRes) String() string { return proto.CompactTextString(m) }
func (*ConsumeRes) ProtoMessage()    {}
func (*ConsumeRes) Descriptor() ([]byte, []int) {
	return fileDescriptor_1f475d2b3bc19ab6, []int{3}
}

func (m *ConsumeRes) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ConsumeRes.Unmarshal(m, b)
}
func (m *ConsumeRes) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ConsumeRes.Marshal(b, m, deterministic)
}
func (m *ConsumeRes) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ConsumeRes.Merge(m, src)
}
func (m *ConsumeRes) XXX_Size() int {
	return xxx_messageInfo_ConsumeRes.Size(m)
}
func (m *ConsumeRes) XXX_DiscardUnknown() {
	xxx_messageInfo_ConsumeRes.DiscardUnknown(m)
}

var xxx_messageInfo_ConsumeRes proto.InternalMessageInfo

func (m *ConsumeRes) GetPartition() int32 {
	if m != nil {
		return m.Partition
	}
	return 0
}

func (m *ConsumeRes) GetOffset() int64 {
	if m != nil {
		return m.Offset
	}
	return 0
}

func (m *ConsumeRes) GetValue() []byte {
	if m != nil {
		return m.Value
	}
	return nil
}

func init() {
	proto.RegisterType((*ProduceRequest)(nil), "ProduceRequest")
	proto.RegisterType((*ProduceRes)(nil), "ProduceRes")
	proto.RegisterType((*ConsumeRequest)(nil), "ConsumeRequest")
	proto.RegisterType((*ConsumeRes)(nil), "ConsumeRes")
}

func init() {
	proto.RegisterFile("kafka/grpc/kafka.proto", fileDescriptor_1f475d2b3bc19ab6)
}

var fileDescriptor_1f475d2b3bc19ab6 = []byte{
	// 270 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x8c, 0x91, 0x41, 0x4b, 0xc3, 0x40,
	0x10, 0x85, 0x8d, 0x21, 0x2d, 0x9d, 0x94, 0x16, 0x16, 0xa9, 0xa1, 0x78, 0x28, 0x39, 0x05, 0x84,
	0xad, 0xe8, 0x3f, 0xa8, 0x47, 0x2f, 0x25, 0x82, 0x88, 0xb7, 0x75, 0xdd, 0x84, 0xd0, 0xa6, 0x13,
	0x77, 0x76, 0xc5, 0x9f, 0x2f, 0x99, 0x26, 0x4d, 0x7b, 0xf3, 0xb6, 0xdf, 0xf0, 0x78, 0x6f, 0xdf,
	0x0c, 0x2c, 0x76, 0xaa, 0xd8, 0xa9, 0x75, 0x69, 0x1b, 0xbd, 0xe6, 0xa7, 0x6c, 0x2c, 0x3a, 0x4c,
	0x3f, 0x60, 0xb6, 0xb5, 0xf8, 0xe5, 0xb5, 0xc9, 0xcd, 0xb7, 0x37, 0xe4, 0x44, 0x02, 0x63, 0xbd,
	0xf7, 0xe4, 0x8c, 0x4d, 0x82, 0x55, 0x90, 0x4d, 0xf2, 0x1e, 0xc5, 0x0d, 0x44, 0x0e, 0x9b, 0x4a,
	0x27, 0xd7, 0x3c, 0x3f, 0x42, 0xab, 0xaf, 0x0d, 0x91, 0x2a, 0x4d, 0x12, 0xae, 0x82, 0x6c, 0x9a,
	0xf7, 0x98, 0x4e, 0x01, 0x4e, 0xde, 0x94, 0xbe, 0xc1, 0xec, 0x19, 0x0f, 0xe4, 0xeb, 0xff, 0x25,
	0x95, 0x16, 0x7d, 0xd3, 0x27, 0x31, 0x0c, 0xf9, 0xe1, 0x59, 0x7e, 0xfa, 0x0e, 0x70, 0xf2, 0x25,
	0x71, 0x07, 0x93, 0x46, 0x59, 0x57, 0xb9, 0x0a, 0x0f, 0xec, 0x1a, 0xe5, 0xc3, 0x40, 0x2c, 0x60,
	0x84, 0x45, 0x41, 0xc6, 0xb1, 0x71, 0x98, 0x77, 0xd4, 0x3a, 0xff, 0xa8, 0xbd, 0xef, 0x1b, 0x1c,
	0xe1, 0x51, 0x41, 0xf4, 0xd2, 0xae, 0x4a, 0xdc, 0xc3, 0xb8, 0x2b, 0x22, 0xe6, 0xf2, 0x72, 0x5d,
	0xcb, 0x58, 0x9e, 0x75, 0xbc, 0x7a, 0x08, 0x5a, 0x71, 0xf7, 0x1f, 0x31, 0x97, 0x97, 0x8d, 0x97,
	0xf1, 0x30, 0x60, 0xf1, 0x26, 0x83, 0x5b, 0x8d, 0xb5, 0x54, 0x56, 0x23, 0xfd, 0x4a, 0xaa, 0x6c,
	0xe5, 0x49, 0xf2, 0x7d, 0x36, 0xf1, 0x2b, 0x13, 0xff, 0x60, 0x1b, 0x7c, 0x8e, 0xf8, 0x5e, 0x4f,
	0x7f, 0x01, 0x00, 0x00, 0xff, 0xff, 0x5b, 0x51, 0x93, 0x8e, 0xc9, 0x01, 0x00, 0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConnInterface

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion6

// KafkaClient is the client API for Kafka service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type KafkaClient interface {
	Produce(ctx context.Context, in *ProduceRequest, opts ...grpc.CallOption) (Kafka_ProduceClient, error)
	Consume(ctx context.Context, in *ConsumeRequest, opts ...grpc.CallOption) (Kafka_ConsumeClient, error)
}

type kafkaClient struct {
	cc grpc.ClientConnInterface
}

func NewKafkaClient(cc grpc.ClientConnInterface) KafkaClient {
	return &kafkaClient{cc}
}

func (c *kafkaClient) Produce(ctx context.Context, in *ProduceRequest, opts ...grpc.CallOption) (Kafka_ProduceClient, error) {
	stream, err := c.cc.NewStream(ctx, &_Kafka_serviceDesc.Streams[0], "/Kafka/Produce", opts...)
	if err != nil {
		return nil, err
	}
	x := &kafkaProduceClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type Kafka_ProduceClient interface {
	Recv() (*ProduceRes, error)
	grpc.ClientStream
}

type kafkaProduceClient struct {
	grpc.ClientStream
}

func (x *kafkaProduceClient) Recv() (*ProduceRes, error) {
	m := new(ProduceRes)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func (c *kafkaClient) Consume(ctx context.Context, in *ConsumeRequest, opts ...grpc.CallOption) (Kafka_ConsumeClient, error) {
	stream, err := c.cc.NewStream(ctx, &_Kafka_serviceDesc.Streams[1], "/Kafka/Consume", opts...)
	if err != nil {
		return nil, err
	}
	x := &kafkaConsumeClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type Kafka_ConsumeClient interface {
	Recv() (*ConsumeRes, error)
	grpc.ClientStream
}

type kafkaConsumeClient struct {
	grpc.ClientStream
}

func (x *kafkaConsumeClient) Recv() (*ConsumeRes, error) {
	m := new(ConsumeRes)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// KafkaServer is the server API for Kafka service.
type KafkaServer interface {
	Produce(*ProduceRequest, Kafka_ProduceServer) error
	Consume(*ConsumeRequest, Kafka_ConsumeServer) error
}

// UnimplementedKafkaServer can be embedded to have forward compatible implementations.
type UnimplementedKafkaServer struct {
}

func (*UnimplementedKafkaServer) Produce(req *ProduceRequest, srv Kafka_ProduceServer) error {
	return status.Errorf(codes.Unimplemented, "method Produce not implemented")
}
func (*UnimplementedKafkaServer) Consume(req *ConsumeRequest, srv Kafka_ConsumeServer) error {
	return status.Errorf(codes.Unimplemented, "method Consume not implemented")
}

func RegisterKafkaServer(s *grpc.Server, srv KafkaServer) {
	s.RegisterService(&_Kafka_serviceDesc, srv)
}

func _Kafka_Produce_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(ProduceRequest)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(KafkaServer).Produce(m, &kafkaProduceServer{stream})
}

type Kafka_ProduceServer interface {
	Send(*ProduceRes) error
	grpc.ServerStream
}

type kafkaProduceServer struct {
	grpc.ServerStream
}

func (x *kafkaProduceServer) Send(m *ProduceRes) error {
	return x.ServerStream.SendMsg(m)
}

func _Kafka_Consume_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(ConsumeRequest)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(KafkaServer).Consume(m, &kafkaConsumeServer{stream})
}

type Kafka_ConsumeServer interface {
	Send(*ConsumeRes) error
	grpc.ServerStream
}

type kafkaConsumeServer struct {
	grpc.ServerStream
}

func (x *kafkaConsumeServer) Send(m *ConsumeRes) error {
	return x.ServerStream.SendMsg(m)
}

var _Kafka_serviceDesc = grpc.ServiceDesc{
	ServiceName: "Kafka",
	HandlerType: (*KafkaServer)(nil),
	Methods:     []grpc.MethodDesc{},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "Produce",
			Handler:       _Kafka_Produce_Handler,
			ServerStreams: true,
		},
		{
			StreamName:    "Consume",
			Handler:       _Kafka_Consume_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "kafka/grpc/kafka.proto",
}
